{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock market prediction based on patent novelty - Topic based novelty measures\n",
    "\n",
    "In this file, we make predictions using within-sector novelty measures based on the topics derived from the LDA model. In file `3_2_Stock_prices_prediction_within_sector_BoW.ipynb`, we make predictions using within-sector novelty measures based on the vector of words, and we summarize and compare the results obtained in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 15)\n",
      "(369810, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/all_novelty_within_sector.csv\")\n",
    "df = df.drop(columns=['bow_avg_similarity_5','bow_avg_similarity_10', 'bow_avg_similarity_20']) #drop words-based similarity measures\n",
    "stock_prices = pd.read_csv(\"../data/stockprices_2000_2020.csv\")\n",
    "print(df.shape)\n",
    "print(stock_prices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "CL     335\n",
       "CHD     70\n",
       "HSY     18\n",
       "CPB      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ticker.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a sample with 4 companies, some of which are much more innovative than others (more patents granted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21132, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices = stock_prices[(stock_prices[\"Ticker\"]==\"CL\") | \n",
    "                            (stock_prices[\"Ticker\"]==\"CHD\") |\n",
    "                            (stock_prices[\"Ticker\"]==\"HSY\") |\n",
    "                            (stock_prices[\"Ticker\"]==\"CPB\")]\n",
    "stock_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping range of dates for which we have patent data\n",
    "\n",
    "stock_prices[\"date\"] = pd.to_datetime(stock_prices[\"Date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"issue_date\"])\n",
    "stock_prices = stock_prices[(stock_prices[\"date\"]>=df.date.min()) &\n",
    "                            (stock_prices[\"date\"]<=df.date.max())]\n",
    "stock_prices = stock_prices.drop(columns=[\"Date\"])\n",
    "\n",
    "stock_prices = stock_prices.rename(columns={'Ticker': 'ticker'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145157</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.013531</td>\n",
       "      <td>2010-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145158</th>\n",
       "      <td>CHD</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>2010-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145159</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>2010-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145160</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>2010-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145161</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>2010-01-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker  Adj Close       date\n",
       "145157    CHD  -0.013531 2010-01-05\n",
       "145158    CHD   0.004792 2010-01-06\n",
       "145159    CHD  -0.011184 2010-01-07\n",
       "145160    CHD  -0.002162 2010-01-08\n",
       "145161    CHD  -0.004334 2010-01-11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have several cases of more than one patent granted for the same company in the same day, we need to take some aggregated measures - we take both the average similarity measures as well as the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many patents are published on the same date - we take average and max \n",
    "\n",
    "df_reduc = df.drop(columns=[\"text\", \"patent_id\", \"clean_corpus\", \"issue_date\"])\n",
    "df2_avg = df_reduc.groupby(['ticker', 'date', 'sector']).mean().reset_index()\n",
    "df2_max = df_reduc.groupby(['ticker', 'date', 'sector']).max().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'numpat_total', 'sector', 'lda_avg_similarity_5',\n",
       "       'lda_avg_similarity_10', 'lda_avg_similarity_20', 'nw', 'nb', 'nt',\n",
       "       'nwc', 'nov', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to exclude from renaming\n",
    "exclude_cols = ['ticker', 'date', 'sector', 'numpat_total', 'nw', 'nb', 'nt', 'nwc', 'nov']\n",
    "# Mapping dictionary for renaming max cols\n",
    "rename_dict_max = {col: col + '_max' for col in df2_max.columns if col not in exclude_cols}\n",
    "# Mapping dictionary for renaming avg cols\n",
    "rename_dict_avg = {col: col + '_avg' for col in df2_avg.columns if col not in exclude_cols}\n",
    "\n",
    "# Rename the columns\n",
    "df2_max.rename(columns=rename_dict_max, inplace=True)\n",
    "df2_avg.rename(columns=rename_dict_avg, inplace=True)\n",
    "df2_max = df2_max.drop(columns=['nw', 'nb', 'nt', 'nwc','nov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8928, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the two datasets\n",
    "merged = pd.merge(stock_prices, df2_avg, on=[\"date\", \"ticker\"], how=\"left\")\n",
    "merged = pd.merge(merged, df2_max, on=[\"date\", \"ticker\", \"sector\", \"numpat_total\"], how=\"left\")\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>date</th>\n",
       "      <th>sector</th>\n",
       "      <th>numpat_total</th>\n",
       "      <th>lda_avg_similarity_5_avg</th>\n",
       "      <th>lda_avg_similarity_10_avg</th>\n",
       "      <th>lda_avg_similarity_20_avg</th>\n",
       "      <th>nw</th>\n",
       "      <th>nb</th>\n",
       "      <th>nt</th>\n",
       "      <th>nwc</th>\n",
       "      <th>nov</th>\n",
       "      <th>lda_avg_similarity_5_max</th>\n",
       "      <th>lda_avg_similarity_10_max</th>\n",
       "      <th>lda_avg_similarity_20_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.013531</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHD</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  Adj Close       date sector  numpat_total  lda_avg_similarity_5_avg   \n",
       "0    CHD  -0.013531 2010-01-05    NaN           NaN                       NaN  \\\n",
       "1    CHD   0.004792 2010-01-06    NaN           NaN                       NaN   \n",
       "2    CHD  -0.011184 2010-01-07    NaN           NaN                       NaN   \n",
       "3    CHD  -0.002162 2010-01-08    NaN           NaN                       NaN   \n",
       "4    CHD  -0.004334 2010-01-11    NaN           NaN                       NaN   \n",
       "\n",
       "   lda_avg_similarity_10_avg  lda_avg_similarity_20_avg  nw  nb  nt  nwc  nov   \n",
       "0                        NaN                        NaN NaN NaN NaN  NaN  NaN  \\\n",
       "1                        NaN                        NaN NaN NaN NaN  NaN  NaN   \n",
       "2                        NaN                        NaN NaN NaN NaN  NaN  NaN   \n",
       "3                        NaN                        NaN NaN NaN NaN  NaN  NaN   \n",
       "4                        NaN                        NaN NaN NaN NaN  NaN  NaN   \n",
       "\n",
       "   lda_avg_similarity_5_max  lda_avg_similarity_10_max   \n",
       "0                       NaN                        NaN  \\\n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "   lda_avg_similarity_20_max  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a dataset with a lot of NA values, since we have data for 8928 days/tickers, but new patents were only released in 256 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"../data/stockprices_novelty_merged_sector_lda.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only take at this point a few preprocessing steps: dropping the variable for sector (as we are only working with one), getting the total number of patents for each company, filling NAs with 0 for the novelty measures (0 signalling no innovation), and transforming the column 'date' into date format.\n",
    "\n",
    "It is worth noting that in previous version of this exercise, we included other features (such as lags and rolling means of the novelty measures), but they did not add value to the predictions, so here we keep the simpler version.\n",
    "\n",
    "We set the start of the test set in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/stockprices_novelty_merged_sector_lda.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Sector does not give us extra information\n",
    "\n",
    "df = df.drop(columns=[\"sector\"])\n",
    "\n",
    "# Calculate the maximum value within each group\n",
    "numpatents = df.groupby('ticker')['numpat_total'].transform('max')\n",
    "\n",
    "# Assign the maximum values to a new column 'max_value'\n",
    "df['numpat_total'] = numpatents\n",
    "\n",
    "test_time_start = '2017'\n",
    "\n",
    "df = df.fillna(0) # Filling NAs with 0 (signaling \"no innovation\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "df.sort_values(['ticker', 'date'], inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "\n",
    "+ Naive model\n",
    "\n",
    "We start by building a naive prediction model that forecasts the future values of the target variable using the last known value for each observation. This approach assumes that the future values of the target variable will be similar to the previous observed values, making it a simple baseline model for comparison with more sophisticated prediction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01842054595810413\n"
     ]
    }
   ],
   "source": [
    "test_time_start = '2017-01-01'\n",
    "train = df.loc[df.date < test_time_start]\n",
    "test = df.loc[df.date >= test_time_start]\n",
    "\n",
    "companies = df['ticker'].unique()\n",
    "\n",
    "def apply_naive_prediction(train, test, target, companies):\n",
    "    y_pred = []  # Initialize y_pred as an empty list\n",
    "    for c in companies:\n",
    "        train_c = train[train[\"ticker\"]==c]\n",
    "        test_c = test[test[\"ticker\"]==c]\n",
    "\n",
    "        y_pred_1 = train_c[target].iloc[-1]\n",
    "        y_pred_2 = test_c[target].shift(1)  # Shift the values by 1 timestep\n",
    "        y_pred_c = y_pred_2.fillna(y_pred_1)\n",
    "        y_pred.append(y_pred_c)  # Append the predicted values to y_pred list\n",
    "\n",
    "    return pd.concat(y_pred)  # Concatenate the predicted values into a single series or dataframe\n",
    "\n",
    "\n",
    "y_pred = apply_naive_prediction(train, test, \"Adj Close\", companies)\n",
    "\n",
    "mse_naive = mean_squared_error(test[\"Adj Close\"], y_pred, squared=False)\n",
    "print(\"Mean Squared Error:\", mse_naive)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Our first model for generating prediction is a machine learning approach, particularly random forest model. We consider:\n",
    "\n",
    "+ Fixed effects by company (ticker dummies).\n",
    "+ Include past information for stock market variation (rolling means for 3, 6, 15, 30, 60, 120 days)\n",
    "+ Model: RF + hyperparameter tunning\n",
    "+ 2 versions: with and without novelty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting target by 1 day\n",
    "\n",
    "# Function for defining Y variable\n",
    "\n",
    "def make_target(df, t):\n",
    "    '''t is the number of periods to shift forward'''\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(by=['ticker', 'date'])\n",
    "\n",
    "    # loop through each period and generate the shift variables\n",
    "    for i in range(1, t+1):\n",
    "        col_name = f'Adj Close{i}'\n",
    "        df[col_name] = df.groupby(['ticker'])['Adj Close'].shift(-i)\n",
    "\n",
    "    # take the maximum for t periods forward and create the new variable\n",
    "    df['target_f{}'.format(t)] = df[[f'Adj Close{i}' for i in range(1, t+1)]].max(axis=1, skipna=False)\n",
    "\n",
    "    # drop the shift variables\n",
    "    df = df.drop(columns=[f'Adj Close{i}' for i in range(1, t+1)])\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>date</th>\n",
       "      <th>numpat_total</th>\n",
       "      <th>lda_avg_similarity_5_avg</th>\n",
       "      <th>lda_avg_similarity_10_avg</th>\n",
       "      <th>lda_avg_similarity_20_avg</th>\n",
       "      <th>nw</th>\n",
       "      <th>nb</th>\n",
       "      <th>nt</th>\n",
       "      <th>nwc</th>\n",
       "      <th>nov</th>\n",
       "      <th>lda_avg_similarity_5_max</th>\n",
       "      <th>lda_avg_similarity_10_max</th>\n",
       "      <th>lda_avg_similarity_20_max</th>\n",
       "      <th>target_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>HSY</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>HSY</td>\n",
       "      <td>-0.009070</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>HSY</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>HSY</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>HSY</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.553247</td>\n",
       "      <td>0.565704</td>\n",
       "      <td>0.488136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553247</td>\n",
       "      <td>0.565704</td>\n",
       "      <td>0.488136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker  Adj Close       date  numpat_total  lda_avg_similarity_5_avg   \n",
       "8923    HSY   0.003343 2018-11-07          27.0                  0.000000  \\\n",
       "8924    HSY  -0.009070 2018-11-08          27.0                  0.000000   \n",
       "8925    HSY   0.014103 2018-11-09          27.0                  0.000000   \n",
       "8926    HSY   0.000829 2018-11-12          27.0                  0.000000   \n",
       "8927    HSY   0.004325 2018-11-13          27.0                  0.553247   \n",
       "\n",
       "      lda_avg_similarity_10_avg  lda_avg_similarity_20_avg   nw   nb   nt   \n",
       "8923                   0.000000                   0.000000  0.0  0.0  0.0  \\\n",
       "8924                   0.000000                   0.000000  0.0  0.0  0.0   \n",
       "8925                   0.000000                   0.000000  0.0  0.0  0.0   \n",
       "8926                   0.000000                   0.000000  0.0  0.0  0.0   \n",
       "8927                   0.565704                   0.488136  0.0  0.0  0.0   \n",
       "\n",
       "      nwc  nov  lda_avg_similarity_5_max  lda_avg_similarity_10_max   \n",
       "8923  0.0  0.0                  0.000000                   0.000000  \\\n",
       "8924  0.0  0.0                  0.000000                   0.000000   \n",
       "8925  0.0  0.0                  0.000000                   0.000000   \n",
       "8926  0.0  0.0                  0.000000                   0.000000   \n",
       "8927  0.0  0.0                  0.553247                   0.565704   \n",
       "\n",
       "      lda_avg_similarity_20_max  target_f1  \n",
       "8923                   0.000000  -0.009070  \n",
       "8924                   0.000000   0.014103  \n",
       "8925                   0.000000   0.000829  \n",
       "8926                   0.000000   0.004325  \n",
       "8927                   0.488136        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = make_target(df, 1)\n",
    "df_target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate variables for the past 3 to 120 days with a rolling mean of Adj Close\n",
    "df_target[\"date\"] = pd.to_datetime(df_target[\"date\"])\n",
    "panel_data= df_target.copy()\n",
    "panel_data = panel_data.sort_values(by=['ticker', 'date'])\n",
    "lcols = (panel_data.groupby(['ticker'])['Adj Close'] \n",
    "         .transform(lambda x: x.rolling(w, min_periods=1).mean()) # rolling mean\n",
    "         .rename('past' + str(w-1)) \n",
    "         for w in [4, 7, 16, 31, 61, 121])\n",
    "panel_data = panel_data.join(pd.DataFrame(lcols).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE for ticker\n",
    "\n",
    "dummies = pd.get_dummies(panel_data['ticker'], dtype=int)\n",
    "merged = pd.concat([panel_data, dummies], axis=1)\n",
    "\n",
    "merged = merged.drop(columns=[\"ticker\", \"Adj Close\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Model including novelty measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test \n",
    "train = merged.loc[merged.date < test_time_start]\n",
    "test = merged.loc[merged.date >= test_time_start]\n",
    "test = test.dropna()\n",
    "\n",
    "X_train = train.drop('target_f1', axis=1).drop(columns=[\"date\"])  # Features\n",
    "y_train = train['target_f1']  # Target variable\n",
    "X_test = test.drop('target_f1', axis=1).drop(columns=[\"date\"])  # Features\n",
    "y_test = test['target_f1']  # Target variable\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply the scaler to both the training and test features\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0001708550032204425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Model with novelty measures\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'max_depth': [None, 5, 7, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_imp(coef, names):\n",
    "    imp = coef\n",
    "    indexes = np.argsort(imp)[-11:]\n",
    "    indexes = list(indexes)\n",
    "    \n",
    "    plt.barh(range(len(indexes)), imp[indexes], align='center')\n",
    "    plt.yticks(range(len(indexes)), [names[i] for i in indexes])\n",
    "    plt.show()\n",
    "    \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[18, 8, 7, 0, 6, 15, 17, 16, 14, 13, 12]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "feature_imp(abs(best_model.feature_importances_), feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can interpret that the features with the highest importance are the variables related to the historic stock market values: past 3, past 6, past 15, past 60, past 120 and past 30. These are the variables that are more significant to the model's prediction power. The novelty measures do not seem to be the most important features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Model excluding novelty measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['numpat_total', 'lda_avg_similarity_5_avg', 'lda_avg_similarity_10_avg',\n",
       "       'lda_avg_similarity_20_avg', 'nw', 'nb', 'nt', 'nwc', 'nov',\n",
       "       'lda_avg_similarity_5_max', 'lda_avg_similarity_10_max',\n",
       "       'lda_avg_similarity_20_max', 'past3', 'past6', 'past15', 'past30',\n",
       "       'past60', 'past120', 'CHD', 'CL', 'CPB', 'HSY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude novelty measures\n",
    "novel_vars = ['lda_avg_similarity_5_avg', 'lda_avg_similarity_10_avg',\n",
    "       'lda_avg_similarity_20_avg', 'nw', 'nb', 'nt', 'nwc', 'nov',\n",
    "       'lda_avg_similarity_5_max', 'lda_avg_similarity_10_max',\n",
    "       'lda_avg_similarity_20_max']\n",
    "\n",
    "X_train_no_novel = X_train.drop(columns=novel_vars)\n",
    "X_test_no_novel = X_test.drop(columns=novel_vars)\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features\n",
    "scaler.fit(X_train_no_novel)\n",
    "\n",
    "# Apply the scaler to both the training and test features\n",
    "X_train_no_novel_scaled = scaler.transform(X_train_no_novel)\n",
    "X_test_no_novel_scaled = scaler.transform(X_test_no_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0001709835569661605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Model without novelty measures\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'max_depth': [None, 5, 7, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search_no_novel = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_no_novel.fit(X_train_no_novel_scaled, y_train)\n",
    "\n",
    "best_model_no_novel = grid_search_no_novel.best_estimator_\n",
    "\n",
    "y_pred_no_novel = best_model_no_novel.predict(X_test_no_novel_scaled)\n",
    "mse_no_novel = mean_squared_error(y_test, y_pred_no_novel)\n",
    "print(\"Mean Squared Error:\", mse_no_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAGdCAYAAACirV9DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7DElEQVR4nO3df1RVdb7/8dcWOkeUX6OAgEJIovgjhMQfXK9KacN4G6/NOGXpumo6WgqFkmMxDZpRwZQJwjiW46SONplOao0ZzkiDa03+wNFw/B1WCCXoHctDmgLB/v5Rnrnn608UZAPPx1p75dn78/ns9z471nmtz9n7bMM0TVMAAACwnDZNXQAAAAAuj6AGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFuTd1Abg5dXV1OnHihLy8vGQYRlOXAwAAroNpmvr6668VHBysNm2uPG9GUGvmTpw4oZCQkKYuAwAA3ICysjJ16dLlitsJas2cl5eXpO9OtLe3dxNXAwAArkdlZaVCQkKcn+NXQlBr5i5+3ent7U1QAwCgmbnWZUvcTAAAAGBRBDUAAACLIqgBAABYFEENAADAoghqAAAAFkVQAwAAsCiCGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFEENAADAoghqAAAAFuXe1AWgYfSZt0Vt7O2augwAAFqMksz7mroEZtQAAACsiqAGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQaWUlJiQzDUFFRkcv69evXKzY2Vr6+vmrfvr2io6O1atWqpikSAABYEk8maCIdOnTQM888o8jISNlsNm3atEmPPPKIAgIClJCQ0NTlAQAAC2BGTVJ8fLySkpKUlJQkHx8f+fn5KS0tTaZpSpJWrVql2NhYeXl5KTAwUOPGjdOpU6ec/b/66iuNHz9e/v7+8vDwUEREhJYvXy5J6tq1qyQpJiZGhmEoPj7euc+f/OQn6tmzp+644w4lJycrKipKf//732/twQMAAMsiqH1v5cqVcnd3V2FhoRYtWqSFCxdq2bJlkqSamhqlp6dr37592rhxo0pKSjRp0iRn37S0NB06dEjvv/++Dh8+rCVLlsjPz0+SVFhYKEnaunWrysvLtX79+kv2bZqm8vPzdfToUQ0dOvSqdVZVVamystJlAQAALRNffX4vJCREWVlZMgxDPXr00P79+5WVlaWpU6dq8uTJznbh4eHKyclR//79dfbsWXl6eqq0tFQxMTGKjY2VJIWFhTnb+/v7S5I6duyowMBAl306HA517txZVVVVcnNz029/+1vde++9V60zIyND8+fPb6CjBgAAVsaM2vcGDRokwzCcr+Pi4lRcXKza2lrt2bNHo0aNUmhoqLy8vDRs2DBJUmlpqSRp+vTpWrNmjaKjozVnzhxt3779uvbp5eWloqIi7d69Wy+88IJSUlJUUFBw1T6pqalyOBzOpays7MYOGAAAWB5B7RouXLighIQEeXt764033tDu3bu1YcMGSVJ1dbUkaeTIkTp+/LhmzZqlEydOaPjw4Zo9e/Y1x27Tpo26deum6OhoPfnkk/rZz36mjIyMq/ax2+3y9vZ2WQAAQMtEUPverl27XF7v3LlTEREROnLkiE6fPq3MzEwNGTJEkZGRLjcSXOTv76+JEydq9erVys7O1tKlSyVJNptNklRbW3vNGurq6lRVVdUARwMAAFoCrlH7XmlpqVJSUvToo49q7969ys3N1SuvvKLQ0FDZbDbl5ubqscce04EDB5Senu7Sd+7cuerXr5969+6tqqoqbdq0ST179pQkBQQEyMPDQ3l5eerSpYvatm0rHx8fZWRkKDY2VnfccYeqqqq0efNmrVq1SkuWLGmKwwcAABbEjNr3JkyYoPPnz2vAgAFKTExUcnKypk2bJn9/f61YsULr1q1Tr169lJmZqQULFrj0tdlsSk1NVVRUlIYOHSo3NzetWbNGkuTu7q6cnBy99tprCg4O1ujRoyVJ586d04wZM9S7d28NHjxYb7/9tlavXq2f//znt/zYAQCANRnmxR8La8Xi4+MVHR2t7Ozspi6l3iorK+Xj46OQmWvVxt6uqcsBAKDFKMm8r9HGvvj57XA4rnq9OTNqAAAAFkVQAwAAsChuJpCu+dtlAAAATYEZNQAAAIsiqAEAAFgUX322EAfmJ/CUAgAAWhhm1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFEENAADAoghqAAAAFsXPc7QQfeZt4aHsAIBGfZA4bj1m1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFEENAADAoghqAAAAFkVQAwAAsCiCWiMrKSmRYRgqKiq6ZNuZM2eUmJiooKAg2e12de/eXZs3b771RQIAAEviB2+bSHV1te69914FBAToT3/6kzp37qzjx4/L19e3qUsDAAAWwYyapPj4eCUlJSkpKUk+Pj7y8/NTWlqaTNOUJK1atUqxsbHy8vJSYGCgxo0bp1OnTjn7f/XVVxo/frz8/f3l4eGhiIgILV++XJLUtWtXSVJMTIwMw1B8fLwk6fXXX9eXX36pjRs3avDgwQoLC9OwYcPUt2/fW3vwAADAsghq31u5cqXc3d1VWFioRYsWaeHChVq2bJkkqaamRunp6dq3b582btyokpISTZo0ydk3LS1Nhw4d0vvvv6/Dhw9ryZIl8vPzkyQVFhZKkrZu3ary8nKtX79ekvTuu+8qLi5OiYmJ6tSpk/r06aMXX3xRtbW1V62zqqpKlZWVLgsAAGiZ+OrzeyEhIcrKypJhGOrRo4f279+vrKwsTZ06VZMnT3a2Cw8PV05Ojvr376+zZ8/K09NTpaWliomJUWxsrCQpLCzM2d7f31+S1LFjRwUGBjrXf/rpp/rggw80fvx4bd68WceOHdOMGTNUU1OjefPmXbHOjIwMzZ8/v4GPHgAAWBEzat8bNGiQDMNwvo6Li1NxcbFqa2u1Z88ejRo1SqGhofLy8tKwYcMkSaWlpZKk6dOna82aNYqOjtacOXO0ffv2a+6vrq5OAQEBWrp0qfr166exY8fqmWee0auvvnrVfqmpqXI4HM6lrKzsJo4aAABYGUHtGi5cuKCEhAR5e3vrjTfe0O7du7VhwwZJ390QIEkjR47U8ePHNWvWLJ04cULDhw/X7NmzrzpuUFCQunfvLjc3N+e6nj17qqKiwjnu5djtdnl7e7ssAACgZSKofW/Xrl0ur3fu3KmIiAgdOXJEp0+fVmZmpoYMGaLIyEiXGwku8vf318SJE7V69WplZ2dr6dKlkiSbzSZJl1x7NnjwYB07dkx1dXXOdR9//LGCgoKcfQAAQOtGUPteaWmpUlJSdPToUb355pvKzc1VcnKyQkNDZbPZlJubq08//VTvvvuu0tPTXfrOnTtX77zzjo4dO6aDBw9q06ZN6tmzpyQpICBAHh4eysvL08mTJ+VwOCR993Xpl19+qeTkZH388cd677339OKLLyoxMfGWHzsAALAmgtr3JkyYoPPnz2vAgAFKTExUcnKypk2bJn9/f61YsULr1q1Tr169lJmZqQULFrj0tdlsSk1NVVRUlIYOHSo3NzetWbNGkuTu7q6cnBy99tprCg4O1ujRoyV9d/PCli1btHv3bkVFRemJJ55QcnKynn766Vt+7AAAwJoM8+KPhbVi8fHxio6OVnZ2dlOXUm+VlZXy8fFRyMy1amNv19TlAACaWEnmfU1dAq7Dxc9vh8Nx1evNmVEDAACwKIIaAACARfGDt5IKCgqaugQAAIBLMKMGAABgUQQ1AAAAi+KrzxbiwPwEnlIAAEALw4waAACARRHUAAAALIqgBgAAYFEENQAAAIsiqAEAAFgUQQ0AAMCi+HmOFqLPvC08lB1Aq8LDx9EaMKMGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdRuQklJiQzDUFFRkcv6gwcPasyYMQoLC5NhGMrOzr6k77PPPivDMFyWyMjIW1M4AABoFvjB20bwzTffKDw8XA888IBmzZp1xXa9e/fW1q1bna/d3TkdAADg31r8jFp8fLySkpKUlJQkHx8f+fn5KS0tTaZpSpJWrVql2NhYeXl5KTAwUOPGjdOpU6ec/b/66iuNHz9e/v7+8vDwUEREhJYvXy5J6tq1qyQpJiZGhmEoPj5ektS/f3+9/PLLeuihh2S3269Ym7u7uwIDA52Ln59fI70LAACgOWrxQU2SVq5cKXd3dxUWFmrRokVauHChli1bJkmqqalRenq69u3bp40bN6qkpESTJk1y9k1LS9OhQ4f0/vvv6/Dhw1qyZIkzUBUWFkqStm7dqvLycq1fv75edRUXFys4OFjh4eEaP368SktLr9mnqqpKlZWVLgsAAGiZWsV3bSEhIcrKypJhGOrRo4f279+vrKwsTZ06VZMnT3a2Cw8PV05Ojvr376+zZ8/K09NTpaWliomJUWxsrCQpLCzM2d7f31+S1LFjRwUGBtarpoEDB2rFihXq0aOHysvLNX/+fA0ZMkQHDhyQl5fXFftlZGRo/vz59doXAABonlrFjNqgQYNkGIbzdVxcnIqLi1VbW6s9e/Zo1KhRCg0NlZeXl4YNGyZJztmt6dOna82aNYqOjtacOXO0ffv2Bqlp5MiReuCBBxQVFaWEhARt3rxZZ86c0dq1a6/aLzU1VQ6Hw7mUlZU1SD0AAMB6WkVQu5ILFy4oISFB3t7eeuONN7R7925t2LBBklRdXS3pu0B1/PhxzZo1SydOnNDw4cM1e/bsBq/F19dX3bt317Fjx67azm63y9vb22UBAAAtU6sIart27XJ5vXPnTkVEROjIkSM6ffq0MjMzNWTIEEVGRrrcSHCRv7+/Jk6cqNWrVys7O1tLly6VJNlsNklSbW3tTdd49uxZffLJJwoKCrrpsQAAQMvQKoJaaWmpUlJSdPToUb355pvKzc1VcnKyQkNDZbPZlJubq08//VTvvvuu0tPTXfrOnTtX77zzjo4dO6aDBw9q06ZN6tmzpyQpICBAHh4eysvL08mTJ+VwOCR9NxtXVFSkoqIiVVdX64svvlBRUZHLbNns2bO1bds2lZSUaPv27frJT34iNzc3Pfzww7fujQEAAJbWKoLahAkTdP78eQ0YMECJiYlKTk7WtGnT5O/vrxUrVmjdunXq1auXMjMztWDBApe+NptNqampioqK0tChQ+Xm5qY1a9ZI+u7nNXJycvTaa68pODhYo0ePliSdOHFCMTExiomJUXl5uRYsWKCYmBj9/Oc/d477+eef6+GHH1aPHj304IMPqmPHjtq5c6fzBgUAAADDvPiDYi1UfHy8oqOjL/t0gJagsrJSPj4+Cpm5Vm3s7Zq6HAC4ZUoy72vqEoAbdvHz2+FwXPV681YxowYAANAcEdQAAAAsqsX/4G1BQUFTlwAAAHBDmFEDAACwKIIaAACARRHUAAAALKrFX6PWWhyYn8DjpAAAaGGYUQMAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAi+Kuzxaiz7wtPJQdQJPjQelAw2JGDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAiyKo3YSSkhIZhqGioqJLtp05c0aJiYkKCgqS3W5X9+7dtXnzZpc2ixcvVlhYmNq2bauBAweqsLDwFlUOAACaA37wthFUV1fr3nvvVUBAgP70pz+pc+fOOn78uHx9fZ1t3nrrLaWkpOjVV1/VwIEDlZ2drYSEBB09elQBAQFNVzwAALCMFj+jFh8fr6SkJCUlJcnHx0d+fn5KS0uTaZqSpFWrVik2NlZeXl4KDAzUuHHjdOrUKWf/r776SuPHj5e/v788PDwUERGh5cuXS5K6du0qSYqJiZFhGIqPj5ckvf766/ryyy+1ceNGDR48WGFhYRo2bJj69u3rHHfhwoWaOnWqHnnkEfXq1Uuvvvqq2rVrp9dff/0WvTMAAMDqWnxQk6SVK1fK3d1dhYWFWrRokRYuXKhly5ZJkmpqapSenq59+/Zp48aNKikp0aRJk5x909LSdOjQIb3//vs6fPiwlixZIj8/P0lyflW5detWlZeXa/369ZKkd999V3FxcUpMTFSnTp3Up08fvfjii6qtrZX03Yzbnj17NGLECOd+2rRpoxEjRmjHjh1XPZaqqipVVla6LAAAoGVqFV99hoSEKCsrS4ZhqEePHtq/f7+ysrI0depUTZ482dkuPDxcOTk56t+/v86ePStPT0+VlpYqJiZGsbGxkqSwsDBne39/f0lSx44dFRgY6Fz/6aef6oMPPtD48eO1efNmHTt2TDNmzFBNTY3mzZunf/3rX6qtrVWnTp1c6uzUqZOOHDly1WPJyMjQ/Pnzb/YtAQAAzUCrmFEbNGiQDMNwvo6Li1NxcbFqa2u1Z88ejRo1SqGhofLy8tKwYcMkSaWlpZKk6dOna82aNYqOjtacOXO0ffv2a+6vrq5OAQEBWrp0qfr166exY8fqmWee0auvvnrTx5KamiqHw+FcysrKbnpMAABgTa0iqF3JhQsXlJCQIG9vb73xxhvavXu3NmzYIOm7ryclaeTIkTp+/LhmzZqlEydOaPjw4Zo9e/ZVxw0KClL37t3l5ubmXNezZ09VVFSourpafn5+cnNz08mTJ136nTx50mVm7nLsdru8vb1dFgAA0DK1iqC2a9cul9c7d+5URESEjhw5otOnTyszM1NDhgxRZGSky40EF/n7+2vixIlavXq1srOztXTpUkmSzWaTJOe1ZxcNHjxYx44dU11dnXPdxx9/rKCgINlsNtlsNvXr10/5+fnO7XV1dcrPz1dcXFyDHTcAAGjeWkVQKy0tVUpKio4ePao333xTubm5Sk5OVmhoqGw2m3Jzc/Xpp5/q3XffVXp6ukvfuXPn6p133tGxY8d08OBBbdq0ST179pQkBQQEyMPDQ3l5eTp58qQcDoek774u/fLLL5WcnKyPP/5Y7733nl588UUlJiY6x01JSdHvfvc7rVy5UocPH9b06dN17tw5PfLII7fujQEAAJbWKoLahAkTdP78eQ0YMECJiYlKTk7WtGnT5O/vrxUrVmjdunXq1auXMjMztWDBApe+NptNqampioqK0tChQ+Xm5qY1a9ZIktzd3ZWTk6PXXntNwcHBGj16tKTvbl7YsmWLdu/eraioKD3xxBNKTk7W008/7Rx37NixWrBggebOnavo6GgVFRUpLy/vkhsMAABA62WYF39QrIWKj49XdHS0srOzm7qURlFZWSkfHx+FzFyrNvZ2TV0OgFauJPO+pi4BaBYufn47HI6rXm/eKmbUAAAAmiOCGgAAgEW1+B+8LSgoaOoSAAAAbggzagAAABZFUAMAALAoghoAAIBFtfhr1FqLA/MTeJwUAAAtDDNqAAAAFkVQAwAAsCiCGgAAgEUR1AAAACyKoAYAAGBR3PXZQvSZt4WHsgOtGA9DB1omZtQAAAAsiqAGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAogtpVlJSUyDAMFRUVuaw/ePCgxowZo7CwMBmGoezs7Ev6ZmRkqH///vLy8lJAQIDuv/9+HT161KXNhQsXlJiYqI4dO8rT01NjxozRyZMnG/GIAABAc0JQuwHffPONwsPDlZmZqcDAwMu22bZtmxITE7Vz50799a9/VU1NjX74wx/q3LlzzjazZs3Sn//8Z61bt07btm3TiRMn9NOf/vRWHQYAALC4Zh/U4uPjlZSUpKSkJPn4+MjPz09paWkyTVOStGrVKsXGxsrLy0uBgYEaN26cTp065ez/1Vdfafz48fL395eHh4ciIiK0fPlySVLXrl0lSTExMTIMQ/Hx8ZKk/v376+WXX9ZDDz0ku91+2bry8vI0adIk9e7dW3379tWKFStUWlqqPXv2SJIcDod+//vfa+HChbrnnnvUr18/LV++XNu3b9fOnTsb6+0CAADNSLMPapK0cuVKubu7q7CwUIsWLdLChQu1bNkySVJNTY3S09O1b98+bdy4USUlJZo0aZKzb1pamg4dOqT3339fhw8f1pIlS+Tn5ydJKiwslCRt3bpV5eXlWr9+/Q3X6HA4JEkdOnSQJO3Zs0c1NTUaMWKEs01kZKRCQ0O1Y8eOK45TVVWlyspKlwUAALRMLeJZnyEhIcrKypJhGOrRo4f279+vrKwsTZ06VZMnT3a2Cw8PV05Ojvr376+zZ8/K09NTpaWliomJUWxsrCQpLCzM2d7f31+S1LFjxyt+xXk96urqNHPmTA0ePFh9+vSRJFVUVMhms8nX19elbadOnVRRUXHFsTIyMjR//vwbrgUAADQfLWJGbdCgQTIMw/k6Li5OxcXFqq2t1Z49ezRq1CiFhobKy8tLw4YNkySVlpZKkqZPn641a9YoOjpac+bM0fbt2xu8vsTERB04cEBr1qy56bFSU1PlcDicS1lZWQNUCAAArKhFBLUruXDhghISEuTt7a033nhDu3fv1oYNGyRJ1dXVkqSRI0fq+PHjmjVrlk6cOKHhw4dr9uzZDVZDUlKSNm3apL/97W/q0qWLc31gYKCqq6t15swZl/YnT5686uyd3W6Xt7e3ywIAAFqmFhHUdu3a5fJ6586dioiI0JEjR3T69GllZmZqyJAhioyMdLmR4CJ/f39NnDhRq1evVnZ2tpYuXSpJstlskqTa2tp612SappKSkrRhwwZ98MEHzhsTLurXr59uu+025efnO9cdPXpUpaWliouLq/f+AABAy9MirlErLS1VSkqKHn30Ue3du1e5ubl65ZVXFBoaKpvNptzcXD322GM6cOCA0tPTXfrOnTtX/fr1U+/evVVVVaVNmzapZ8+ekqSAgAB5eHgoLy9PXbp0Udu2beXj46Pq6modOnRI0nczc1988YWKiork6empbt26Sfru684//vGPeuedd+Tl5eW87szHx0ceHh7y8fHRlClTlJKSog4dOsjb21uPP/644uLiNGjQoFv47gEAAKtqETNqEyZM0Pnz5zVgwAAlJiYqOTlZ06ZNk7+/v1asWKF169apV69eyszM1IIFC1z62mw2paamKioqSkOHDpWbm5vzWjJ3d3fl5OTotddeU3BwsEaPHi1JOnHihGJiYhQTE6Py8nItWLBAMTEx+vnPf+4cd8mSJXI4HIqPj1dQUJBzeeutt5xtsrKy9OMf/1hjxozR0KFDFRgYeFN3lgIAgJbFMC/+4FgzFR8fr+jo6Ms+HaA1qKyslI+Pj0JmrlUbe7umLgdAEynJvK+pSwBQDxc/vx0Ox1WvN28RM2oAAAAtEUENAADAopr9zQQFBQVNXQIAAECjYEYNAADAoghqAAAAFkVQAwAAsKhmf40avnNgfgKPkwIAoIVhRg0AAMCiCGoAAAAWRVADAACwKIIaAACARRHUAAAALIq7PluIPvO28FB2oAXiYetA68aMGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFEENAADAoghqAAAAFkVQu0klJSUyDENFRUUu69evX6/Y2Fj5+vqqffv2io6O1qpVq1zamKapuXPnKigoSB4eHhoxYoSKi4tvYfUAAMDKCGqNpEOHDnrmmWe0Y8cO/fOf/9QjjzyiRx55RFu2bHG2eemll5STk6NXX31Vu3btUvv27ZWQkKALFy40YeUAAMAqWkVQi4+PV1JSkpKSkuTj4yM/Pz+lpaXJNE1J0qpVqxQbGysvLy8FBgZq3LhxOnXqlLP/V199pfHjx8vf318eHh6KiIjQ8uXLJUldu3aVJMXExMgwDMXHxzv3+ZOf/EQ9e/bUHXfcoeTkZEVFRenvf/+7pO9m07Kzs/WrX/1Ko0ePVlRUlP7whz/oxIkT2rhx4617cwAAgGW1iqAmSStXrpS7u7sKCwu1aNEiLVy4UMuWLZMk1dTUKD09Xfv27dPGjRtVUlKiSZMmOfumpaXp0KFDev/993X48GEtWbJEfn5+kqTCwkJJ0tatW1VeXq7169dfsm/TNJWfn6+jR49q6NChkqTPPvtMFRUVGjFihLOdj4+PBg4cqB07dlzxOKqqqlRZWemyAACAlqnVPOszJCREWVlZMgxDPXr00P79+5WVlaWpU6dq8uTJznbh4eHKyclR//79dfbsWXl6eqq0tFQxMTGKjY2VJIWFhTnb+/v7S5I6duyowMBAl306HA517txZVVVVcnNz029/+1vde++9kqSKigpJUqdOnVz6dOrUybntcjIyMjR//vwbfyMAAECz0Wpm1AYNGiTDMJyv4+LiVFxcrNraWu3Zs0ejRo1SaGiovLy8NGzYMElSaWmpJGn69Olas2aNoqOjNWfOHG3fvv269unl5aWioiLt3r1bL7zwglJSUlRQUHBTx5GamiqHw+FcysrKbmo8AABgXa0mqF3JhQsXlJCQIG9vb73xxhvavXu3NmzYIEmqrq6WJI0cOVLHjx/XrFmzdOLECQ0fPlyzZ8++5tht2rRRt27dFB0drSeffFI/+9nPlJGRIUnO2beTJ0+69Dl58uQlM3P/l91ul7e3t8sCAABaplYT1Hbt2uXyeufOnYqIiNCRI0d0+vRpZWZmasiQIYqMjHS5keAif39/TZw4UatXr1Z2draWLl0qSbLZbJKk2traa9ZQV1enqqoqSd/dhBAYGKj8/Hzn9srKSu3atUtxcXE3fJwAAKDlaDXXqJWWliolJUWPPvqo9u7dq9zcXL3yyisKDQ2VzWZTbm6uHnvsMR04cEDp6ekufefOnat+/fqpd+/eqqqq0qZNm9SzZ09JUkBAgDw8PJSXl6cuXbqobdu28vHxUUZGhmJjY3XHHXeoqqpKmzdv1qpVq7RkyRJJkmEYmjlzpp5//nlFRESoa9euSktLU3BwsO6///5b/fYAAAALajVBbcKECTp//rwGDBggNzc3JScna9q0aTIMQytWrNAvf/lL5eTk6K677tKCBQv03//9386+NptNqampKikpkYeHh4YMGaI1a9ZIktzd3ZWTk6PnnntOc+fO1ZAhQ1RQUKBz585pxowZ+vzzz+Xh4aHIyEitXr1aY8eOdY47Z84cnTt3TtOmTdOZM2f0n//5n8rLy1Pbtm1v+fsDAACsxzAv/phYCxYfH6/o6GhlZ2c3dSkNrrKyUj4+PgqZuVZt7O2auhwADawk876mLgFAI7j4+e1wOK56vXmruUYNAACguSGoAQAAWFSruEbtZn+7DAAAoCkwowYAAGBRBDUAAACLIqgBAABYVKu4Rq01ODA/gcdJAQDQwjCjBgAAYFEENQAAAIsiqAEAAFgUQQ0AAMCiCGoAAAAWxV2fLUSfeVsa7KHsPAQaAABrYEYNAADAoghqAAAAFkVQAwAAsCiCGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqhZyKRJk3T//fc3dRkAAMAiWk1QKygokGEYOnPmzHX3iY+P18yZM+u9rxvtBwAA8H+1mqAGAADQ3NQrqMXHx+uJJ57QnDlz1KFDBwUGBurZZ5+VJJWUlMgwDBUVFTnbnzlzRoZhqKCgQNK/Z7W2bNmimJgYeXh46J577tGpU6f0/vvvq2fPnvL29ta4ceP0zTffuOw3KSlJSUlJ8vHxkZ+fn9LS0mSaprPNqlWrFBsbKy8vLwUGBmrcuHE6deqUs7a7775bkvSDH/xAhmFo0qRJVz3WSZMmadu2bVq0aJEMw5BhGCopKZEkbdu2TQMGDJDdbldQUJCefvppffvtt1ftV1tbqylTpqhr167y8PBQjx49tGjRovq8/QAAoJWp94zaypUr1b59e+3atUsvvfSSnnvuOf31r3+t1xjPPvusfvOb32j79u0qKyvTgw8+qOzsbP3xj3/Ue++9p7/85S/Kzc29ZL/u7u4qLCzUokWLtHDhQi1btsy5vaamRunp6dq3b582btyokpISZxgLCQnR22+/LUk6evSoysvLrxmSFi1apLi4OE2dOlXl5eUqLy9XSEiIvvjiC/3Xf/2X+vfvr3379mnJkiX6/e9/r+eff/6q/erq6tSlSxetW7dOhw4d0ty5c/XLX/5Sa9eurdd7V1VVpcrKSpcFAAC0TPV+KHtUVJTmzZsnSYqIiNBvfvMb5efnKyIi4rrHeP755zV48GBJ0pQpU5SamqpPPvlE4eHhkqSf/exn+tvf/qannnrK2SckJERZWVkyDEM9evTQ/v37lZWVpalTp0qSJk+e7GwbHh6unJwc9e/fX2fPnpWnp6c6dOggSQoICJCvr+81a/Tx8ZHNZlO7du0UGBjoXP/b3/5WISEh+s1vfiPDMBQZGakTJ07oqaee0ty5c6/Yz83NTfPnz3e+7tq1q3bs2KG1a9fqwQcfvO73LiMjw2UcAADQctV7Ri0qKsrldVBQkPMrxhsZo1OnTmrXrp0zpF1c9/+POWjQIBmG4XwdFxen4uJi1dbWSpL27NmjUaNGKTQ0VF5eXho2bJgkqbS0tF61Xcvhw4cVFxfnUsvgwYN19uxZff7551ftu3jxYvXr10/+/v7y9PTU0qVL611famqqHA6HcykrK7uh4wAAANZX76B22223ubw2DEN1dXVq0+a7of7vdWM1NTXXHMMwjCuOeb3OnTunhIQEeXt764033tDu3bu1YcMGSVJ1dfV1j9OY1qxZo9mzZ2vKlCn6y1/+oqKiIj3yyCP1rs9ut8vb29tlAQAALVO9v/q8En9/f0lSeXm5YmJiJMnlxoKbtWvXLpfXO3fuVEREhNzc3HTkyBGdPn1amZmZCgkJkST94x//cGlvs9kkyTkDdz1sNtsl7Xv27Km3335bpmk6Z9U+/PBDeXl5qUuXLlfs9+GHH+o//uM/NGPGDOe6Tz755LprAQAArU+D/TyHh4eHBg0apMzMTB0+fFjbtm3Tr371q4YaXqWlpUpJSdHRo0f15ptvKjc3V8nJyZKk0NBQ2Ww25ebm6tNPP9W7776r9PR0l/633367DMPQpk2b9L//+786e/bsNfcZFhamXbt2qaSkRP/6179UV1enGTNmqKysTI8//riOHDmid955R/PmzVNKSopzVvFy/SIiIvSPf/xDW7Zs0ccff6y0tDTt3r27wd4fAADQ8jTo76i9/vrr+vbbb9WvXz/NnDnTeSdkQ5gwYYLOnz+vAQMGKDExUcnJyZo2bZqk72bzVqxYoXXr1qlXr17KzMzUggULXPp37txZ8+fP19NPP61OnTopKSnpmvucPXu23Nzc1KtXL/n7+6u0tFSdO3fW5s2bVVhYqL59++qxxx7TlClTXELp5fo9+uij+ulPf6qxY8dq4MCBOn36tMvsGgAAwP/PMP/vRWUWFR8fr+joaGVnZzd1KZZTWVkpHx8fhcxcqzb2dg0yZknmfQ0yDgAAuLyLn98Oh+Oq15vzZAIAAACLarVBrbS0VJ6enldcGvpnPQAAAOqrwe76bEwXH0HVkIKDg696V2pwcHCD7xMAAKA+mkVQawzu7u7q1q1bU5cBAABwRa32q08AAACra7Uzai3NgfkJPKUAAIAWhhk1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAo7vpsIfrM23Ldz/rkWZ4AADQPzKgBAABYFEENAADAoghqAAAAFkVQAwAAsCiCGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqjVQ0VFhR5//HGFh4fLbrcrJCREo0aNUn5+viQpLCxM2dnZl/R79tlnFR0d7fLaMAwZhiF3d3f5+flp6NChys7OVlVV1S06GgAAYHU8meA6lZSUaPDgwfL19dXLL7+sO++8UzU1NdqyZYsSExN15MiReo3Xu3dvbd26VXV1dTp9+rQKCgr0/PPPa9WqVSooKJCXl1cjHQkAAGguCGrXacaMGTIMQ4WFhWrfvr1zfe/evTV58uR6j+fu7q7AwEBJUnBwsO68807de++96tu3r37961/r+eefb7DaAQBA88RXn9fhyy+/VF5enhITE11C2kW+vr4Nsp/IyEiNHDlS69evv2KbqqoqVVZWuiwAAKBlIqhdh2PHjsk0TUVGRl6z7VNPPSVPT0+X5cUXX7zufUVGRqqkpOSK2zMyMuTj4+NcQkJCrntsAADQvBDUroNpmtfd9he/+IWKiopclscee6xe+zIM44rbU1NT5XA4nEtZWdl1jw0AAJoXrlG7DhERETIM47puGPDz81O3bt1c1nXo0OG693X48GF17dr1itvtdrvsdvt1jwcAAJovZtSuQ4cOHZSQkKDFixfr3Llzl2w/c+ZMg+znyJEjysvL05gxYxpkPAAA0LwR1K7T4sWLVVtbqwEDBujtt99WcXGxDh8+rJycHMXFxdV7vG+//VYVFRU6ceKE9u/fr9zcXA0bNkzR0dH6xS9+0QhHAAAAmhu++rxO4eHh2rt3r1544QU9+eSTKi8vl7+/v/r166clS5bUe7yDBw8qKChIbm5u8vHxUa9evZSamqrp06fz1SYAAJAkGWZ9rpSH5VRWVn539+fMtWpjb3ddfUoy72vkqgAAwNVc/Px2OBzy9va+Yju++gQAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAi+LnOVqIA/MTrnrXCAAAaH6YUQMAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAi+Kuzxaiz7wtLs/65HmeAAA0f8yoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAiyKoNbKKigo9/vjjCg8Pl91uV0hIiEaNGqX8/HxJUlhYmLKzs5u2SAAAYEk8maARlZSUaPDgwfL19dXLL7+sO++8UzU1NdqyZYsSExN15MiRpi4RAABYGEGtEc2YMUOGYaiwsFDt27d3ru/du7cmT57chJUBAIDmgKDWSL788kvl5eXphRdecAlpF/n6+t7QuFVVVaqqqnK+rqysvNESAQCAxXGNWiM5duyYTNNUZGRkg46bkZEhHx8f5xISEtKg4wMAAOsgqDUS0zQbZdzU1FQ5HA7nUlZW1ij7AQAATY+vPhtJRESEDMNo8BsG7Ha77HZ7g44JAACsiRm1RtKhQwclJCRo8eLFOnfu3CXbz5w5c+uLAgAAzQpBrREtXrxYtbW1GjBggN5++20VFxfr8OHDysnJUVxcnLPdF198oaKiIpflq6++asLKAQCAFRDUGlF4eLj27t2ru+++W08++aT69Omje++9V/n5+VqyZImz3YIFCxQTE+OyvPfee01YOQAAsALDbKyr3nFLVFZWfnf358y1amNv51xfknlfE1YFAACu5uLnt8PhkLe39xXbMaMGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABbFkwlaiAPzE6561wgAAGh+mFEDAACwKIIaAACARRHUAAAALIqgBgAAYFEENQAAAIsiqLUQfeZtUdjTPMgdAICWhKAGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQAAAAsiqB2AyZNmqT777//kvUFBQUyDENnzpyRJP3ud79T37595enpKV9fX8XExCgjI0OSNGXKFN15552qrq52GWPz5s2y2Wzau3dvYx8GAACwOIJaI3n99dc1c+ZMPfHEEyoqKtKHH36oOXPm6OzZs5KkrKwsff3115o3b56zz5kzZzR16lSlpaXprrvuaqrSAQCARbg3dQEt1bvvvqsHH3xQU6ZMca7r3bu389/e3t5avny5EhISdP/992vgwIGaOXOmOnfurNTU1KYoGQAAWAxBrZEEBgZq27ZtOn78uG6//fbLtrn77rs1Y8YMTZw4Uenp6Vq7dq327t0rd/crn5aqqipVVVU5X1dWVjZ47QAAwBr46vMGbdq0SZ6eni7LyJEjndvnzZsnX19fhYWFqUePHpo0aZLWrl2ruro6l3EuXrP20EMP6cUXX1RkZORV95uRkSEfHx/nEhIS0vAHBwAALIGgdoPuvvtuFRUVuSzLli1zbg8KCtKOHTu0f/9+JScn69tvv9XEiRP1ox/9yCWseXh4aPbs2WrXrp2Sk5Ovud/U1FQ5HA7nUlZW1ijHBwAAmh5ffd6g9u3bq1u3bi7rPv/880va9enTR3369NGMGTP02GOPaciQIdq2bZvuvvtuZxt3d3e5ubnJMIxr7tdut8tut9/8AQAAAMtjRu0W6tWrlyTp3LlzTVwJAABoDphRayTTp09XcHCw7rnnHnXp0kXl5eV6/vnn5e/vr7i4uKYuDwAANAPMqDWSESNGaOfOnXrggQfUvXt3jRkzRm3btlV+fr46duzY1OUBAIBmwDBN02zqInDjKisrv7v7c+ZatbG3U0nmfU1dEgAAuIaLn98Oh0Pe3t5XbMeMGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFL+j1kIcmJ9w1btGAABA88OMGgAAgEUR1AAAACyKoAYAAGBRBDUAAACLIqgBAABYFEENAADAoghqLUSfeVsU9vR7TV0GAABoQAQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQAAAAsiqB2gyoqKvT4448rPDxcdrtdISEhGjVqlPLz8yVJYWFhMgxDhmGoffv2uuuuu7Ru3Tpn/2effda53TAM+fj4aMiQIdq2bVtTHRIAALAYgtoNKCkpUb9+/fTBBx/o5Zdf1v79+5WXl6e7775biYmJznbPPfecysvL9dFHH6l///4aO3astm/f7tzeu3dvlZeXq7y8XDt27FBERIR+/OMfy+FwNMVhAQAAiyGo3YAZM2bIMAwVFhZqzJgx6t69u3r37q2UlBTt3LnT2c7Ly0uBgYHq3r27Fi9eLA8PD/35z392bnd3d1dgYKACAwPVq1cvPffcczp79qw+/vjjpjgsAABgMe5NXUBz8+WXXyovL08vvPCC2rdvf8l2X1/fy/Zzd3fXbbfdpurq6stur6qq0vLly+Xr66sePXpccf9VVVWqqqpyvq6srKzfAQAAgGaDoFZPx44dk2maioyMvO4+1dXVeuWVV+RwOHTPPfc41+/fv1+enp6SpG+++UZeXl5666235O3tfcWxMjIyNH/+/Bs/AAAA0Gzw1Wc9maZ53W2feuopeXp6ql27dvr1r3+tzMxM3Xfffc7tPXr0UFFRkYqKirRnzx5Nnz5dDzzwgP7xj39ccczU1FQ5HA7nUlZWdlPHAwAArIsZtXqKiIiQYRg6cuTINdv+4he/0KRJk+Tp6alOnTrJMAyX7TabTd26dXO+jomJ0caNG5Wdna3Vq1dfdky73S673X5zBwEAAJoFZtTqqUOHDkpISNDixYt17ty5S7afOXPG+W8/Pz9169ZNgYGBl4S0K3Fzc9P58+cbqlwAANCMEdRuwOLFi1VbW6sBAwbo7bffVnFxsQ4fPqycnBzFxcVd9zjffvutKioqVFFRoeLiYj3//PM6dOiQRo8e3YjVAwCA5oKvPm9AeHi49u7dqxdeeEFPPvmkysvL5e/vr379+mnJkiXXPc7BgwcVFBQkSWrXrp3uuOMOLVmyRBMmTGis0gEAQDNimPW5Oh6WU1lZKR8fH4XMXKs29nYqybzv2p0AAECTuvj57XA4rvprD3z1CQAAYFEENQAAAIsiqAEAAFgUQQ0AAMCiCGoAAAAWxc9ztBAH5idc9a4RAADQ/DCjBgAAYFEENQAAAIsiqAEAAFgUQQ0AAMCiCGoAAAAWRVADAACwKIIaAACARRHUAAAALIqgBgAAYFEENQAAAIsiqAEAAFgUQQ0AAMCiCGoAAAAWRVADAACwKIIaAACARbk3dQG4OaZpSpIqKyubuBIAAHC9Ln5uX/wcvxKCWjN3+vRpSVJISEgTVwIAAOrr66+/lo+PzxW3E9SauQ4dOkiSSktLr3qicetUVlYqJCREZWVl8vb2bupyIM6JFXFOrIdzcmuZpqmvv/5awcHBV21HUGvm2rT57jJDHx8f/rAsxtvbm3NiMZwT6+GcWA/n5Na5ngkWbiYAAACwKIIaAACARRHUmjm73a558+bJbrc3dSn4HufEejgn1sM5sR7OiTUZ5rXuCwUAAECTYEYNAADAoghqAAAAFkVQAwAAsCiCGgAAgEUR1Cxm8eLFCgsLU9u2bTVw4EAVFhZetf26desUGRmptm3b6s4779TmzZtdtpumqblz5yooKEgeHh4aMWKEiouLG/MQWpyGPieTJk2SYRguy49+9KPGPIQWqT7n5eDBgxozZozCwsJkGIays7NvekxcqqHPybPPPnvJ30pkZGQjHkHLU59z8rvf/U5DhgzRD37wA/3gBz/QiBEjLmnPZ8qtR1CzkLfeekspKSmaN2+e9u7dq759+yohIUGnTp26bPvt27fr4Ycf1pQpU/TRRx/p/vvv1/33368DBw4427z00kvKycnRq6++ql27dql9+/ZKSEjQhQsXbtVhNWuNcU4k6Uc/+pHKy8udy5tvvnkrDqfFqO95+eabbxQeHq7MzEwFBgY2yJhw1RjnRJJ69+7t8rfy97//vbEOocWp7zkpKCjQww8/rL/97W/asWOHQkJC9MMf/lBffPGFsw2fKU3AhGUMGDDATExMdL6ura01g4ODzYyMjMu2f/DBB8377rvPZd3AgQPNRx991DRN06yrqzMDAwPNl19+2bn9zJkzpt1uN998881GOIKWp6HPiWma5sSJE83Ro0c3Sr2tRX3Py/91++23m1lZWQ06JhrnnMybN8/s27dvA1bZutzs/9Pffvut6eXlZa5cudI0TT5TmgozahZRXV2tPXv2aMSIEc51bdq00YgRI7Rjx47L9tmxY4dLe0lKSEhwtv/ss89UUVHh0sbHx0cDBw684pj4t8Y4JxcVFBQoICBAPXr00PTp03X69OmGP4AW6kbOS1OM2Zo05vtXXFys4OBghYeHa/z48SotLb3ZcluFhjgn33zzjWpqatShQwdJfKY0FYKaRfzrX/9SbW2tOnXq5LK+U6dOqqiouGyfioqKq7a/+N/6jIl/a4xzIn33tecf/vAH5efn69e//rW2bdumkSNHqra2tuEPogW6kfPSFGO2Jo31/g0cOFArVqxQXl6elixZos8++0xDhgzR119/fbMlt3gNcU6eeuopBQcHO4MZnylNw72pCwBam4ceesj57zvvvFNRUVG64447VFBQoOHDhzdhZYC1jBw50vnvqKgoDRw4ULfffrvWrl2rKVOmNGFlLV9mZqbWrFmjgoICtW3btqnLadWYUbMIPz8/ubm56eTJky7rT548ecULbQMDA6/a/uJ/6zMm/q0xzsnlhIeHy8/PT8eOHbv5oluBGzkvTTFma3Kr3j9fX191796dv5XrcDPnZMGCBcrMzNRf/vIXRUVFOdfzmdI0CGoWYbPZ1K9fP+Xn5zvX1dXVKT8/X3FxcZftExcX59Jekv76178623ft2lWBgYEubSorK7Vr164rjol/a4xzcjmff/65Tp8+raCgoIYpvIW7kfPSFGO2Jrfq/Tt79qw++eQT/lauw42ek5deeknp6enKy8tTbGysyzY+U5pIU9/NgH9bs2aNabfbzRUrVpiHDh0yp02bZvr6+poVFRWmaZrm//zP/5hPP/20s/2HH35ouru7mwsWLDAPHz5szps3z7ztttvM/fv3O9tkZmaavr6+5jvvvGP+85//NEePHm127drVPH/+/C0/vuaooc/J119/bc6ePdvcsWOH+dlnn5lbt24177rrLjMiIsK8cOFCkxxjc1Tf81JVVWV+9NFH5kcffWQGBQWZs2fPNj/66COzuLj4usfE1TXGOXnyySfNgoIC87PPPjM//PBDc8SIEaafn5956tSpW358zVF9z0lmZqZps9nMP/3pT2Z5eblz+frrr13a8JlyaxHULCY3N9cMDQ01bTabOWDAAHPnzp3ObcOGDTMnTpzo0n7t2rVm9+7dTZvNZvbu3dt87733XLbX1dWZaWlpZqdOnUy73W4OHz7cPHr06K04lBajIc/JN998Y/7whz80/f39zdtuu828/fbbzalTpxIGbkB9zstnn31mSrpkGTZs2HWPiWtr6HMyduxYMygoyLTZbGbnzp3NsWPHmseOHbuFR9T81eec3H777Zc9J/PmzXO24TPl1jNM0zSbYCIPAAAA18A1agAAABZFUAMAALAoghoAAIBFEdQAAAAsiqAGAABgUQQ1AAAAiyKoAQAAWBRBDQAAwKIIagAAABZFUAMAALAoghoAAIBFEdQAAAAs6v8BJd8aZ451pVcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[9, 10, 8, 7, 0, 4, 6, 5, 3, 2, 1]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_train_no_novel.columns\n",
    "\n",
    "feature_imp(abs(best_model_no_novel.feature_importances_), feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous model, the features with the highest importance are the variables related to the historic stock market values: past 3, past 6, past 15, past 60, past 120 and past 30.\n",
    "\n",
    "The mean squared error for both random forest models is practically the same, showing that patent novelty measures do not seem to add accuracy to the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "+ ARIMA - pooled approach\n",
    "\n",
    "As a second model we incorporated an ARIMA model, since it is a popular time series forecasting model that incorporates autoregressive, moving average, and differencing components.\n",
    "\n",
    "For the homework, we generated four models, one per ticker. Here, we opt for a pooled approach that gives us insights about forecasting at the sector level.\n",
    "\n",
    "Similarly as before, we generate two models: including and excluding novelty measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>numpat_total</th>\n",
       "      <th>lda_avg_similarity_5_avg</th>\n",
       "      <th>lda_avg_similarity_10_avg</th>\n",
       "      <th>lda_avg_similarity_20_avg</th>\n",
       "      <th>nw</th>\n",
       "      <th>nb</th>\n",
       "      <th>nt</th>\n",
       "      <th>nwc</th>\n",
       "      <th>nov</th>\n",
       "      <th>lda_avg_similarity_5_max</th>\n",
       "      <th>lda_avg_similarity_10_max</th>\n",
       "      <th>lda_avg_similarity_20_max</th>\n",
       "      <th>company_CHD</th>\n",
       "      <th>company_CL</th>\n",
       "      <th>company_CPB</th>\n",
       "      <th>company_HSY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>-0.013531</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.004792</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-0.011184</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>-0.002162</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>-0.004334</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close  numpat_total  lda_avg_similarity_5_avg  \\\n",
       "date                                                            \n",
       "2010-01-05  -0.013531         395.0                       0.0   \n",
       "2010-01-06   0.004792         395.0                       0.0   \n",
       "2010-01-07  -0.011184         395.0                       0.0   \n",
       "2010-01-08  -0.002162         395.0                       0.0   \n",
       "2010-01-11  -0.004334         395.0                       0.0   \n",
       "\n",
       "            lda_avg_similarity_10_avg  lda_avg_similarity_20_avg   nw   nb  \\\n",
       "date                                                                         \n",
       "2010-01-05                        0.0                        0.0  0.0  0.0   \n",
       "2010-01-06                        0.0                        0.0  0.0  0.0   \n",
       "2010-01-07                        0.0                        0.0  0.0  0.0   \n",
       "2010-01-08                        0.0                        0.0  0.0  0.0   \n",
       "2010-01-11                        0.0                        0.0  0.0  0.0   \n",
       "\n",
       "             nt  nwc  nov  lda_avg_similarity_5_max  \\\n",
       "date                                                  \n",
       "2010-01-05  0.0  0.0  0.0                       0.0   \n",
       "2010-01-06  0.0  0.0  0.0                       0.0   \n",
       "2010-01-07  0.0  0.0  0.0                       0.0   \n",
       "2010-01-08  0.0  0.0  0.0                       0.0   \n",
       "2010-01-11  0.0  0.0  0.0                       0.0   \n",
       "\n",
       "            lda_avg_similarity_10_max  lda_avg_similarity_20_max  company_CHD  \\\n",
       "date                                                                            \n",
       "2010-01-05                        0.0                        0.0            1   \n",
       "2010-01-06                        0.0                        0.0            1   \n",
       "2010-01-07                        0.0                        0.0            1   \n",
       "2010-01-08                        0.0                        0.0            1   \n",
       "2010-01-11                        0.0                        0.0            1   \n",
       "\n",
       "            company_CL  company_CPB  company_HSY  \n",
       "date                                              \n",
       "2010-01-05           0            0            0  \n",
       "2010-01-06           0            0            0  \n",
       "2010-01-07           0            0            0  \n",
       "2010-01-08           0            0            0  \n",
       "2010-01-11           0            0            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timeseries = df.copy()\n",
    "\n",
    "df_timeseries[\"date\"] = pd.to_datetime(df_timeseries[\"date\"])\n",
    "\n",
    "# Set the 'date' column as the index\n",
    "df_timeseries.set_index('date', inplace=True)\n",
    "\n",
    "# Create dummy variables for each company\n",
    "company_dummies = pd.get_dummies(df_timeseries['ticker'], prefix='company', dtype=int)\n",
    "\n",
    "# Concatenate the original data with the company dummies\n",
    "df_timeseries = pd.concat([df_timeseries, company_dummies], axis=1)\n",
    "\n",
    "df_timeseries = df_timeseries.drop(columns=[\"ticker\"])\n",
    "df_timeseries.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Model without exogenous variables (i.e. excluding novelty measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Model: no covariates\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:              Adj Close   No. Observations:                 7044\n",
      "Model:                 ARIMA(1, 1, 1)   Log Likelihood               21888.721\n",
      "Date:                Sat, 24 Jun 2023   AIC                         -43771.441\n",
      "Time:                        19:28:20   BIC                         -43750.862\n",
      "Sample:                             0   HQIC                        -43764.352\n",
      "                               - 7044                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1         -0.0565      0.010     -5.399      0.000      -0.077      -0.036\n",
      "ma.L1         -0.9999      0.027    -36.650      0.000      -1.053      -0.946\n",
      "sigma2         0.0001   3.23e-06     36.132      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):             54301.43\n",
      "Prob(Q):                              0.95   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.20   Skew:                             0.32\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        16.59\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Mean Squared Error: 0.01302360043257723\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Specify the order of the ARIMA model (p, d, q)\n",
    "p = 1  # AR order\n",
    "d = 1  # Differencing order\n",
    "q = 1  # MA order\n",
    "\n",
    "# Separate the target variable (stock values) and covariates from the combined dataset\n",
    "y = df_timeseries['Adj Close']\n",
    "X = df_timeseries.drop(columns=[\"Adj Close\"])\n",
    "\n",
    "# Split the data into train and test based on date\n",
    "test_start_date = pd.to_datetime('2017-01-01')\n",
    "X_train = X[X.index < test_start_date]\n",
    "X_test = X[X.index >= test_start_date]\n",
    "y_train = y[y.index < test_start_date]\n",
    "y_test = y[y.index >= test_start_date]\n",
    "\n",
    "# Standardize the covariates using a scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled arrays back to a DataFrame with original column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Fit the pooled ARIMA model with exogenous variables\n",
    "model = ARIMA(y_train, order=(p, d, q))\n",
    "model_fit_simple = model.fit()\n",
    "\n",
    "print(\"Pooled Model: no covariates\")\n",
    "print(model_fit_simple.summary())\n",
    "\n",
    "# Make predictions on the test set with exogenous variables\n",
    "y_pred_arima_simple = model_fit_simple.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n",
    "\n",
    "# Calculate the mean squared error (MSE) on the test set\n",
    "mse_arima_simple = mean_squared_error(y_test, y_pred_arima_simple, squared=False)\n",
    "print(f\"Mean Squared Error: {mse_arima_simple}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Model with exogenous variables (including novelty measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Model\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:              Adj Close   No. Observations:                 7044\n",
      "Model:                 ARIMA(1, 1, 1)   Log Likelihood               21389.145\n",
      "Date:                Sat, 24 Jun 2023   AIC                         -42740.290\n",
      "Time:                        19:28:44   BIC                         -42609.954\n",
      "Sample:                             0   HQIC                        -42695.392\n",
      "                               - 7044                                         \n",
      "Covariance Type:                  opg                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "numpat_total                  0.0051      0.001      6.779      0.000       0.004       0.007\n",
      "lda_avg_similarity_5_avg      0.0007      0.001      0.510      0.610      -0.002       0.003\n",
      "lda_avg_similarity_10_avg     0.0011      0.003      0.382      0.702      -0.005       0.007\n",
      "lda_avg_similarity_20_avg    -0.0027      0.003     -0.888      0.374      -0.009       0.003\n",
      "nw                           -0.0006      0.001     -1.017      0.309      -0.002       0.001\n",
      "nb                            0.0006      0.001      1.104      0.270      -0.000       0.002\n",
      "nt                         4.258e-05      0.000      0.193      0.847      -0.000       0.000\n",
      "nwc                           0.0001      0.001      0.238      0.812      -0.001       0.001\n",
      "nov                           0.0002      0.001      0.325      0.745      -0.001       0.002\n",
      "lda_avg_similarity_5_max     -0.0003      0.001     -0.178      0.859      -0.003       0.003\n",
      "lda_avg_similarity_10_max    -0.0019      0.003     -0.641      0.521      -0.008       0.004\n",
      "lda_avg_similarity_20_max     0.0027      0.003      0.842      0.400      -0.004       0.009\n",
      "company_CHD                   0.0115      0.003      4.387      0.000       0.006       0.017\n",
      "company_CL                    0.0037      0.001      4.871      0.000       0.002       0.005\n",
      "company_CPB                  -0.0030      0.001     -2.250      0.024      -0.006      -0.000\n",
      "company_HSY                  -0.0124      0.002     -6.317      0.000      -0.016      -0.009\n",
      "ar.L1                        -0.0871      0.011     -8.086      0.000      -0.108      -0.066\n",
      "ma.L1                        -0.7422      0.010    -77.321      0.000      -0.761      -0.723\n",
      "sigma2                        0.0001   9.31e-07    144.347      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  56.14   Jarque-Bera (JB):             32980.99\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.20   Skew:                             0.44\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        13.56\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 3.05e+19. Standard errors may be unstable.\n",
      "Mean Squared Error: 0.04136559242364726\n"
     ]
    }
   ],
   "source": [
    "# Fit the pooled ARIMA model with exogenous variables\n",
    "\n",
    "model = ARIMA(y_train, order=(p, d, q), exog=X_train_scaled)\n",
    "model_fit = model.fit()\n",
    "\n",
    "print(\"Pooled Model\")\n",
    "print(model_fit.summary())\n",
    "\n",
    "# Make predictions on the test set with exogenous variables\n",
    "y_pred_arima = model_fit.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1, exog=X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error (MSE) on the test set\n",
    "mse_arima = mean_squared_error(y_test, y_pred_arima, squared=False)\n",
    "print(f\"Mean Squared Error: {mse_arima}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the MSE of both ARIMA models, one including exogenous variables and one without, it can be concluded that the ARIMA model without additional features performs better than the one that includes the additional features, such as novelty measures and past data.\n",
    "\n",
    "In addition to this, in the ARIMA model including exogenous variables, the novelty measures are not significant at a 95% confidence level. We find some significant features to be (apart from the historical stock market structure) the total number of patents granted at the company level, and company fixed-effects.\n",
    "\n",
    "Final comments on the comparison of the models with different novelty measures can be found in the file   `3_2_Stock_prices_prediction_within_sector_BoW.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
